{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Bayesian Governance Explorer\n",
    "\n",
    "This notebook allows you to explore different scenarios and parameters for the Bayesian vs Checklist audit comparison.\n",
    "\n",
    "**Use this to**:\n",
    "- Test different stress scenarios\n",
    "- Experiment with prior beliefs\n",
    "- Understand prior-likelihood-posterior dynamics\n",
    "- Visualize how quickly Bayesian updates converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the simulation module\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from bayesian_governance_simulation import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Bayesian Updating\n",
    "\n",
    "Let's start simple: observe how a single day's evidence updates your belief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_single_update():\n",
    "    \"\"\"Interactive widget for understanding single Bayesian update\"\"\"\n",
    "    \n",
    "    @widgets.interact(\n",
    "        prior_failures=widgets.IntSlider(min=1, max=20, value=2, description='Prior failures (α):'),\n",
    "        prior_successes=widgets.IntSlider(min=50, max=200, value=98, description='Prior successes (β):'),\n",
    "        observed_failures=widgets.IntSlider(min=0, max=50, value=5, description='Observed failures:'),\n",
    "        observed_total=widgets.IntSlider(min=10, max=200, value=100, description='Observed batches:')\n",
    "    )\n",
    "    def update_plot(prior_failures, prior_successes, observed_failures, observed_total):\n",
    "        \n",
    "        # Calculate distributions\n",
    "        x = np.linspace(0, 0.20, 1000)\n",
    "        \n",
    "        # Prior\n",
    "        prior_dist = stats.beta.pdf(x, prior_failures, prior_successes)\n",
    "        prior_mean = prior_failures / (prior_failures + prior_successes)\n",
    "        \n",
    "        # Likelihood (scaled for visualization)\n",
    "        likelihood = stats.binom.pmf(\n",
    "            observed_failures,\n",
    "            observed_total,\n",
    "            x\n",
    "        )\n",
    "        likelihood_scaled = likelihood / likelihood.max() * prior_dist.max()\n",
    "        \n",
    "        # Posterior\n",
    "        post_alpha = prior_failures + observed_failures\n",
    "        post_beta = prior_successes + (observed_total - observed_failures)\n",
    "        posterior_dist = stats.beta.pdf(x, post_alpha, post_beta)\n",
    "        posterior_mean = post_alpha / (post_alpha + post_beta)\n",
    "        \n",
    "        # Observed rate\n",
    "        observed_rate = observed_failures / observed_total\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        ax.plot(x, prior_dist, 'b--', linewidth=2, label=f'Prior: β({prior_failures}, {prior_successes})')\n",
    "        ax.fill_between(x, prior_dist, alpha=0.2, color='blue')\n",
    "        \n",
    "        ax.plot(x, likelihood_scaled, 'g:', linewidth=2, label='Likelihood (scaled)')\n",
    "        \n",
    "        ax.plot(x, posterior_dist, 'r-', linewidth=3, label=f'Posterior: β({post_alpha}, {post_beta})')\n",
    "        ax.fill_between(x, posterior_dist, alpha=0.3, color='red')\n",
    "        \n",
    "        ax.axvline(observed_rate, color='black', linestyle=':', linewidth=2, \n",
    "                  label=f'Observed: {observed_rate:.1%}')\n",
    "        \n",
    "        ax.axvline(prior_mean, color='blue', alpha=0.5, linestyle='--')\n",
    "        ax.axvline(posterior_mean, color='red', alpha=0.5, linestyle='--')\n",
    "        \n",
    "        ax.set_xlabel('Failure Rate', fontsize=12)\n",
    "        ax.set_ylabel('Probability Density', fontsize=12)\n",
    "        ax.set_title('Bayesian Update: Prior × Likelihood → Posterior', fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='upper right', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add text box with summary\n",
    "        summary = f\"\"\"Prior mean: {prior_mean:.3f}\n",
    "Observed: {observed_rate:.3f}\n",
    "Posterior mean: {posterior_mean:.3f}\n",
    "\n",
    "Shift: {abs(posterior_mean - prior_mean):.3f}\n",
    "        \"\"\"\n",
    "        \n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        ax.text(0.02, 0.97, summary, transform=ax.transAxes, fontsize=10,\n",
    "               verticalalignment='top', bbox=props)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "interactive_single_update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "**Experiment with the sliders**:\n",
    "\n",
    "1. **Strong prior + weak evidence**: Set α=10, β=90 (10% prior belief), then observe just 2 failures in 20 batches (10% observed). Notice the posterior barely moves—prior dominates.\n",
    "\n",
    "2. **Weak prior + strong evidence**: Set α=1, β=1 (50% uninformative prior), then observe 5 failures in 100 batches (5% observed). Posterior immediately shifts to match evidence—data dominates.\n",
    "\n",
    "3. **Conflicting evidence**: Set α=2, β=98 (2% prior), then observe 10 failures in 50 batches (20% observed). Watch the posterior compromise between prior and likelihood.\n",
    "\n",
    "**The Bayesian Learning Principle**: \n",
    "- Prior represents **accumulated knowledge**\n",
    "- Likelihood represents **new evidence**  \n",
    "- Posterior is the **weighted compromise** (weight depends on relative information content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sequential Learning\n",
    "\n",
    "Now let's see how beliefs evolve **over time** as evidence accumulates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_learning_demo(true_rate=0.05, n_days=100, batches_per_day=50, \n",
    "                            prior_alpha=2, prior_beta=98):\n",
    "    \"\"\"Show how Bayesian belief converges to true value over time\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    auditor = BayesianAuditor(prior_alpha=prior_alpha, prior_beta=prior_beta)\n",
    "    \n",
    "    pofs = [auditor.get_pof()]\n",
    "    lowers = []\n",
    "    uppers = []\n",
    "    \n",
    "    for day in range(n_days):\n",
    "        # Generate observations from true process\n",
    "        failures = np.random.binomial(batches_per_day, true_rate)\n",
    "        \n",
    "        # Update belief\n",
    "        auditor.update(failures, batches_per_day)\n",
    "        pofs.append(auditor.get_pof())\n",
    "        \n",
    "        lower, upper = auditor.get_credible_interval()\n",
    "        lowers.append(lower)\n",
    "        uppers.append(upper)\n",
    "    \n",
    "    # Plot convergence\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    days = np.arange(n_days + 1)\n",
    "    \n",
    "    # Top: PoF convergence\n",
    "    ax1.plot(days, pofs, 'b-', linewidth=2, label='Bayesian PoF')\n",
    "    ax1.axhline(true_rate, color='red', linestyle='--', linewidth=2, label='True Rate')\n",
    "    ax1.axhline(pofs[0], color='blue', linestyle=':', alpha=0.5, label='Prior Mean')\n",
    "    \n",
    "    ax1.set_xlabel('Day', fontsize=11)\n",
    "    ax1.set_ylabel('Probability of Failure', fontsize=11)\n",
    "    ax1.set_title(f'Bayesian Convergence (True Rate = {true_rate:.1%})', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Bottom: Uncertainty reduction\n",
    "    uncertainty = np.array(uppers) - np.array(lowers)\n",
    "    ax2.plot(days[1:], uncertainty, 'g-', linewidth=2)\n",
    "    ax2.fill_between(days[1:], 0, uncertainty, alpha=0.3, color='green')\n",
    "    \n",
    "    ax2.set_xlabel('Day', fontsize=11)\n",
    "    ax2.set_ylabel('Credible Interval Width', fontsize=11)\n",
    "    ax2.set_title('Uncertainty Reduction Over Time', fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary stats\n",
    "    final_error = abs(pofs[-1] - true_rate)\n",
    "    initial_error = abs(pofs[0] - true_rate)\n",
    "    \n",
    "    print(f\"\\nConvergence Summary:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"True rate:          {true_rate:.4f}\")\n",
    "    print(f\"Prior mean:         {pofs[0]:.4f} (error: {initial_error:.4f})\")\n",
    "    print(f\"Final posterior:    {pofs[-1]:.4f} (error: {final_error:.4f})\")\n",
    "    print(f\"Error reduction:    {(1 - final_error/initial_error)*100:.1f}%\")\n",
    "    print(f\"Final uncertainty:  {uncertainty[-1]:.4f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "# Run demo\n",
    "sequential_learning_demo(true_rate=0.05, n_days=100, batches_per_day=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to Notice\n",
    "\n",
    "1. **Convergence speed**: PoF reaches true rate within ~20-30 days\n",
    "2. **Uncertainty reduction**: Credible interval narrows as evidence accumulates\n",
    "3. **Asymptotic behavior**: After sufficient data, additional days provide diminishing returns\n",
    "\n",
    "**Try changing parameters**:\n",
    "```python\n",
    "sequential_learning_demo(\n",
    "    true_rate=0.08,        # Different true process\n",
    "    prior_alpha=10,        # Stronger prior\n",
    "    prior_beta=90          # (implies 10% prior belief)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Scenario Explorer\n",
    "\n",
    "Now let's run the full simulation with custom parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_scenarios():\n",
    "    \"\"\"Interactive scenario explorer\"\"\"\n",
    "    \n",
    "    @widgets.interact(\n",
    "        stress_duration=widgets.IntSlider(min=20, max=150, value=100, step=10,\n",
    "                                         description='Stress duration (days):'),\n",
    "        stress_intensity=widgets.FloatSlider(min=0.001, max=0.005, value=0.002, step=0.0005,\n",
    "                                            description='Stress intensity:',\n",
    "                                            readout_format='.4f'),\n",
    "        prior_alpha=widgets.IntSlider(min=1, max=10, value=2,\n",
    "                                     description='Prior α:'),\n",
    "        prior_beta=widgets.IntSlider(min=50, max=150, value=98,\n",
    "                                    description='Prior β:')\n",
    "    )\n",
    "    def run_custom_scenario(stress_duration, stress_intensity, prior_alpha, prior_beta):\n",
    "        \n",
    "        print(f\"Running scenario with custom parameters...\")\n",
    "        print(f\"Prior belief: {prior_alpha/(prior_alpha+prior_beta):.2%}\")\n",
    "        print(f\"Stress period: {stress_duration} days\\n\")\n",
    "        \n",
    "        # Modify ProcessState to use custom stress intensity\n",
    "        # (This is a simplified version; full implementation would subclass ProcessState)\n",
    "        \n",
    "        results = run_simulation(\n",
    "            days=365,\n",
    "            daily_batches=50,\n",
    "            stress_start=150,\n",
    "            stress_end=150 + stress_duration\n",
    "        )\n",
    "        \n",
    "        plot_simulation_results(results)\n",
    "        generate_summary_metrics(results)\n",
    "\n",
    "explore_scenarios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Real-World Calibration Exercise\n",
    "\n",
    "**Challenge**: Last year's audit found 2% failure rate in EBR data integrity. \n",
    "\n",
    "This week you observe:\n",
    "- Monday: 3 failures / 47 batches\n",
    "- Tuesday: 2 failures / 51 batches  \n",
    "- Wednesday: 5 failures / 48 batches\n",
    "- Thursday: 4 failures / 50 batches\n",
    "- Friday: 6 failures / 49 batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with last year's audit as prior\n",
    "auditor = BayesianAuditor(prior_alpha=2, prior_beta=98)\n",
    "\n",
    "print(\"Starting belief (from last year's audit):\")\n",
    "print(f\"  PoF: {auditor.get_pof():.3f}\")\n",
    "lower, upper = auditor.get_credible_interval()\n",
    "print(f\"  95% Credible Interval: [{lower:.3f}, {upper:.3f}]\\n\")\n",
    "\n",
    "# Weekly observations\n",
    "week_data = [\n",
    "    (\"Monday\", 3, 47),\n",
    "    (\"Tuesday\", 2, 51),\n",
    "    (\"Wednesday\", 5, 48),\n",
    "    (\"Thursday\", 4, 50),\n",
    "    (\"Friday\", 6, 49)\n",
    "]\n",
    "\n",
    "print(\"Daily Updates:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for day, failures, total in week_data:\n",
    "    pof = auditor.update(failures, total)\n",
    "    lower, upper = auditor.get_credible_interval()\n",
    "    observed_rate = failures / total\n",
    "    \n",
    "    print(f\"{day:12} | Observed: {observed_rate:.1%} ({failures}/{total})\")\n",
    "    print(f\"             | Updated PoF: {pof:.3f} [{lower:.3f}, {upper:.3f}]\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "# Final assessment\n",
    "final_pof = auditor.get_pof()\n",
    "week_avg = sum(f for _, f, _ in week_data) / sum(t for _, _, t in week_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WEEK SUMMARY:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Week average observed rate: {week_avg:.1%}\")\n",
    "print(f\"Final Bayesian PoF:         {final_pof:.1%}\")\n",
    "print(f\"Shift from prior:           +{(final_pof - 0.02)*100:.1f}pp\")\n",
    "\n",
    "if final_pof > 0.06:\n",
    "    print(\"\\n⚠️  CRITICAL: PoF > 6% → Immediate escalation required\")\n",
    "elif final_pof > 0.03:\n",
    "    print(\"\\n⚠️  WARNING: PoF > 3% → Investigate within 48 hours\")\n",
    "else:\n",
    "    print(\"\\n✓ Normal: PoF within baseline range\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Framework\n",
    "\n",
    "**Traditional Checklist Approach**:  \n",
    "\"We'll review this at next quarterly audit (60 days away)\"\n",
    "\n",
    "**Bayesian Governance Approach**:  \n",
    "\"PoF crossed 3% threshold on Wednesday → triggered investigation protocol → root cause identified by Friday\"\n",
    "\n",
    "**The Difference**: ~55 days of lead time to prevent manifold fracture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Building Intuition for Priors\n",
    "\n",
    "**Key Question**: How do you choose α and β?\n",
    "\n",
    "### Method 1: Pseudo-counts\n",
    "\n",
    "Think of α and β as \"imaginary\" prior observations:\n",
    "- α = number of failures you've \"seen\"\n",
    "- β = number of successes you've \"seen\"\n",
    "\n",
    "Example: Last year's audit sampled 100 batches, found 2 failures\n",
    "→ Use `Beta(2, 98)` as prior\n",
    "\n",
    "### Method 2: Belief + Confidence\n",
    "\n",
    "- **Belief**: What failure rate do you expect? (sets α/(α+β))\n",
    "- **Confidence**: How sure are you? (sets α+β, the \"effective sample size\")\n",
    "\n",
    "Examples:\n",
    "- `Beta(2, 98)`: 2% belief, low confidence (n_eff = 100)\n",
    "- `Beta(20, 980)`: 2% belief, high confidence (n_eff = 1000)\n",
    "- `Beta(1, 1)`: 50% belief, zero confidence (uninformative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prior_selection():\n",
    "    \"\"\"Compare different priors with same mean but different confidence\"\"\"\n",
    "    \n",
    "    target_mean = 0.02  # 2% belief\n",
    "    \n",
    "    priors = [\n",
    "        (\"Weak\", 2, 98),         # n_eff = 100\n",
    "        (\"Medium\", 20, 980),     # n_eff = 1000\n",
    "        (\"Strong\", 200, 9800),   # n_eff = 10000\n",
    "    ]\n",
    "    \n",
    "    x = np.linspace(0, 0.08, 1000)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for name, alpha, beta in priors:\n",
    "        dist = stats.beta.pdf(x, alpha, beta)\n",
    "        ax.plot(x, dist, linewidth=2, label=f'{name}: β({alpha}, {beta})')\n",
    "        ax.fill_between(x, dist, alpha=0.2)\n",
    "    \n",
    "    ax.axvline(target_mean, color='black', linestyle='--', linewidth=2, \n",
    "              label='Target mean (2%)')\n",
    "    \n",
    "    ax.set_xlabel('Failure Rate', fontsize=12)\n",
    "    ax.set_ylabel('Probability Density', fontsize=12)\n",
    "    ax.set_title('Prior Selection: Same Belief, Different Confidence', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Weak:   'I think it's 2%, but I'm not very sure'\")\n",
    "    print(\"        → Wide distribution, updates quickly with new data\")\n",
    "    print(\"\\nMedium: 'I'm fairly confident it's around 2%'\")\n",
    "    print(\"        → Narrower distribution, moderate update rate\")\n",
    "    print(\"\\nStrong: 'I'm very confident it's 2% based on years of data'\")\n",
    "    print(\"        → Very narrow distribution, updates slowly\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "visualize_prior_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways for Implementation\n",
    "\n",
    "### When to Use Bayesian Governance\n",
    "\n",
    "✅ **Good fits**:\n",
    "- High-frequency processes (daily/weekly observations)\n",
    "- Critical controls where early detection matters\n",
    "- Processes with historical baseline data\n",
    "- Situations requiring quantified uncertainty\n",
    "\n",
    "❌ **Poor fits**:\n",
    "- Rare events (annual occurrence)\n",
    "- Processes with no historical data\n",
    "- Static compliance checklists\n",
    "- Purely qualitative assessments\n",
    "\n",
    "### Implementation Checklist\n",
    "\n",
    "1. **Data infrastructure**: Can you capture daily/weekly observations?\n",
    "2. **Ground truth**: Do you have labeled examples of \"failure\"?\n",
    "3. **Prior calibration**: What's your baseline from historical audits?\n",
    "4. **Threshold definition**: What PoF triggers investigation?\n",
    "5. **Response protocol**: What happens when threshold is crossed?\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "- **Overconfident priors**: Using α+β >> actual sample size\n",
    "- **Ignoring structural breaks**: Model assumes stationary process\n",
    "- **Poor calibration**: Not validating coverage of credible intervals\n",
    "- **Alert fatigue**: Setting thresholds too low\n",
    "- **Lack of action**: Monitoring without governance response\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: Bayesian governance is not about perfect prediction. It's about **honest quantification** of what you know, what you don't know, and how your knowledge evolves as evidence accumulates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
